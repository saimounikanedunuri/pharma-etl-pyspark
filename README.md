# ğŸ’Š Pharma ETL Pipeline with PySpark (Databricks)

This project simulates a real-time ETL pipeline using PySpark for a pharmaceutical dataset. It's structured for interview preparation and covers hands-on practice across 10 hours.

## ğŸ“ Project Structure
- `data/` â€“ Raw pharma CSV file
- `notebooks/` â€“ Databricks notebook with step-by-step ETL process
- `scripts/` â€“ (Optional) PySpark script version
- `README.md` â€“ Project details and usage

## ğŸš€ Key Features
- Data validation & cleaning
- Business rules (e.g., flag high-dosage prescriptions)
- Window functions, Joins, Aggregations
- Partitioned writes in Parquet format
- Interview Q&A scenarios

## ğŸ’» Tools Used
- PySpark (Databricks)
- Python 3.x
- Git & GitHub

## ğŸ“¦ How to Run
1. Clone this repo
2. Upload to Databricks workspace
3. Run step-by-step in notebook

## ğŸ§  Built For
- Data Engineer Interview Practice
- PySpark Real-Time Simulation
- Resume/Portfolio Enhancement

---

ğŸ“Œ **Author:** [Your Name]  
ğŸ”— **LinkedIn:** [Your LinkedIn Profile]  
ğŸ“ **Dataset Size:** 1000 records (synthetic)
