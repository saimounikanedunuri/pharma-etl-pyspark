# 💊 Pharma ETL Pipeline with PySpark (Databricks)

This project simulates a real-time ETL pipeline using PySpark for a pharmaceutical dataset. It's structured for interview preparation and covers hands-on practice across 10 hours.

## 📁 Project Structure
- `data/` – Raw pharma CSV file
- `notebooks/` – Databricks notebook with step-by-step ETL process
- `scripts/` – (Optional) PySpark script version
- `README.md` – Project details and usage

## 🚀 Key Features
- Data validation & cleaning
- Business rules (e.g., flag high-dosage prescriptions)
- Window functions, Joins, Aggregations
- Partitioned writes in Parquet format
- Interview Q&A scenarios

## 💻 Tools Used
- PySpark (Databricks)
- Python 3.x
- Git & GitHub

## 📦 How to Run
1. Clone this repo
2. Upload to Databricks workspace
3. Run step-by-step in notebook

## 🧠 Built For
- Data Engineer Interview Practice
- PySpark Real-Time Simulation
- Resume/Portfolio Enhancement

---

📌 **Author:** [Your Name]  
🔗 **LinkedIn:** [Your LinkedIn Profile]  
📁 **Dataset Size:** 1000 records (synthetic)
